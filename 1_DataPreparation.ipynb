{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c7a1ec4-5260-4c0a-be58-c3fde653c437",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870cbea-46cf-4f2a-99f5-f6a24ec4c2bc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff460fcb-0c6a-47a1-b99d-c430a4619453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from dichasus_cf0x import full_dataset_freq_domain, full_dataset_time_domain\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ea463-2f10-495b-9fea-c605482193c4",
   "metadata": {},
   "source": [
    "## From TensorFlow to NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e95af18-33d5-4d1b-8d89-ff8505c022d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq domain\n",
    "cfos_raw = []\n",
    "csi_freq_domain_raw = []\n",
    "groundtruth_positions_raw = []\n",
    "snrs_raw = []\n",
    "timestamps_raw = []\n",
    "\n",
    "for i, (cfo, csi, pos, snr, time) in enumerate(full_dataset_freq_domain):\n",
    "    cfos_raw.append(cfo.numpy())\n",
    "    csi_freq_domain_raw.append(csi.numpy())\n",
    "    groundtruth_positions_raw.append(pos.numpy())\n",
    "    snrs_raw.append(snr.numpy())\n",
    "    timestamps_raw.append(time.numpy())\n",
    "\n",
    "cfos_raw = np.asarray(cfos_raw)\n",
    "csi_freq_domain_raw = np.asarray(csi_freq_domain_raw)\n",
    "groundtruth_positions_raw = np.asarray(groundtruth_positions_raw)\n",
    "snrs_raw = np.asarray(snrs_raw)\n",
    "timestamps_raw = np.asarray(timestamps_raw)\n",
    "\n",
    "indices_raw = np.arange(timestamps_raw.shape[0])\n",
    "\n",
    "# time domain\n",
    "csi_time_domain = []\n",
    "\n",
    "for i, (csi) in enumerate(full_dataset_time_domain):\n",
    "    csi_time_domain.append(csi.numpy())\n",
    "\n",
    "csi_time_domain = np.asarray(csi_time_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8f94f2-6471-42b3-84da-a06979e5904b",
   "metadata": {},
   "source": [
    "## Compensate for CFOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a081cb3a-6ca6-4256-a023-5fe5bb8d6b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83403, 4, 2, 4, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fc = 1.272e9\n",
    "Fs = 50.056e6\n",
    "SUBCARRIERS = csi_freq_domain_raw.shape[-1]\n",
    "\n",
    "# compensate for CFOs\n",
    "timestamp_diffs = np.concatenate([[0], np.round(np.diff(timestamps_raw) / 0.048) * 0.048])\n",
    "cumulative_cfos = np.cumsum(timestamp_diffs[:,np.newaxis] * cfos_raw, axis = 0)\n",
    "\n",
    "mean_cumulative_cfos = np.mean(cumulative_cfos, axis = 1)\n",
    "initial_sto = -np.angle(np.sum(csi_freq_domain_raw[0,:,:,:,1:] * np.conj(csi_freq_domain_raw[0,:,:,:,:-1]))) / (2 * np.pi) * SUBCARRIERS\n",
    "predicted_stos = initial_sto - mean_cumulative_cfos / Fc * Fs\n",
    "predicted_cpos = -2 * np.pi * mean_cumulative_cfos\n",
    "phaseshift = np.exp(-1.0j * predicted_cpos).astype(np.csingle)\n",
    "timeshift = np.exp(-1.0j * 2 * np.pi * np.outer(predicted_stos, np.arange(-SUBCARRIERS // 2, SUBCARRIERS // 2) / SUBCARRIERS)).astype(np.csingle)\n",
    "predicted_csi = phaseshift[:,np.newaxis] * timeshift\n",
    "\n",
    "csi_freq_domain = csi_freq_domain_raw * np.conj(predicted_csi[:,np.newaxis,np.newaxis,np.newaxis,:])\n",
    "\n",
    "csi_freq_domain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2893898-7af2-4f1a-b010-b0eac4b6e028",
   "metadata": {},
   "source": [
    "## Bring indices in correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e2559e-b439-4672-a386-500e7ab1794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce large timestamp jumps to max. 140 * sample time\n",
    "for i in range(1,timestamps_raw.shape[0]):\n",
    "    if (timestamps_raw[i] - timestamps_raw[i-1] >= 0.048*140):\n",
    "        timestamps_raw[i:] -= (timestamps_raw[i] - (timestamps_raw[i-1] + 0.048*140))\n",
    "\n",
    "#### get valid indices ####\n",
    "# create list of true indices based on timestamps\n",
    "index_list = np.round((timestamps_raw-timestamps_raw[0])/0.048).astype(int)\n",
    "\n",
    "# valid indices for time series\n",
    "valid_indices = -1*np.ones((index_list[-1]+1), dtype=np.int32)\n",
    "valid_indices[index_list] = index_list\n",
    "\n",
    "# valid indices for raw dataset\n",
    "raw_valid_indices = -1*np.ones((index_list[-1]+1), dtype=np.int32)\n",
    "raw_valid_indices[index_list] = indices_raw\n",
    "\n",
    "# timestamps\n",
    "timestamps = -1*np.ones((index_list[-1]+1), dtype=np.float32)\n",
    "timestamps[index_list] = timestamps_raw\n",
    "\n",
    "# get indices for training set and prediction set\n",
    "filter_train = np.arange(valid_indices.shape[0]) % 4 == 0\n",
    "filter_pred = (np.arange(valid_indices.shape[0]) + 2) % 4 == 0\n",
    "\n",
    "# get valid indices for training set and prediction set\n",
    "valid_indices_train = valid_indices[filter_train]\n",
    "valid_indices_pred = valid_indices[filter_pred]\n",
    "\n",
    "# timestamps for training set and prediction set\n",
    "timestamps_train = timestamps[valid_indices_train[np.where(valid_indices_train>=0)]]\n",
    "timestamps_pred = timestamps[valid_indices_pred[np.where(valid_indices_pred>=0)]]\n",
    "\n",
    "# get valid indices in raw dataset for training and prediction set\n",
    "raw_valid_indices_train = raw_valid_indices[valid_indices_train[np.where(valid_indices_train>=0)]]\n",
    "raw_valid_indices_pred = raw_valid_indices[valid_indices_pred[np.where(valid_indices_pred>=0)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e389ccbf-2522-46fd-a853-f4efe32d4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "csi_freq_domain_train = csi_freq_domain[raw_valid_indices_train]\n",
    "csi_time_domain_train = csi_time_domain[raw_valid_indices_train]\n",
    "groundtruth_positions_train = groundtruth_positions_raw[raw_valid_indices_train]\n",
    "snrs_train = snrs_raw[raw_valid_indices_train]\n",
    "\n",
    "# prediction set\n",
    "csi_freq_domain_pred = csi_freq_domain[raw_valid_indices_pred]\n",
    "csi_time_domain_pred = csi_time_domain[raw_valid_indices_pred]\n",
    "groundtruth_positions_pred = groundtruth_positions_raw[raw_valid_indices_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba0edd-758b-4fbe-bfa5-c95346bfa06a",
   "metadata": {},
   "source": [
    "## Save Data as NumPy Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "684dcce1-711b-4868-9f76-74c0a386210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set\n",
    "np.save('dataset/csi_freq_domain_train.npy', csi_freq_domain_train)\n",
    "np.save('dataset/csi_time_domain_train.npy', csi_time_domain_train)\n",
    "np.save('dataset/groundtruth_positions_train.npy', groundtruth_positions_train)\n",
    "np.save('dataset/timestamps_train.npy', timestamps_train)\n",
    "\n",
    "# prediction set\n",
    "np.save('dataset/csi_freq_domain_pred.npy', csi_freq_domain_pred)\n",
    "np.save('dataset/csi_time_domain_pred.npy', csi_time_domain_pred)\n",
    "np.save('dataset/groundtruth_positions_pred.npy', groundtruth_positions_pred)\n",
    "np.save('dataset/timestamps_pred.npy', timestamps_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
